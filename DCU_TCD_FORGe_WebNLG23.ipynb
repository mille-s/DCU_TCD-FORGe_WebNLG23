{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/DCU_TCD-FORGe_WebNLG23/blob/main/DCU_TCD_FORGe_WebNLG23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EixVIRHmxqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deee644-9165-45a5-c826-c9ad64b2ac0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working folder ready!\n",
            "--------------\n",
            "Installing Java 8...\n",
            "\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_382\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_382-8u382-ga-1~22.04.1-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to download and unzip the working folder and install Java 8\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "# clone main repo\n",
        "! git clone https://github.com/mille-s/DCU_TCD-FORGe_WebNLG23.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'DCU_TCD-FORGe_WebNLG23/DCU_TCD_FORGe_WebNLG23.ipynb'\n",
        "\n",
        "# clone M-FleNS repo (generation pipeline)\n",
        "! git clone https://github.com/mille-s/M-FleNS_NLG-Pipeline.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'M-FleNS_NLG-Pipeline/M_FleNS_pipe_v2.ipynb'\n",
        "\n",
        "# Download FORGe\n",
        "# Version used for WebNLG (fails to generate a few structures of the training data)\n",
        "! gdown 1lsh8pwUp9mc0Z_aFbSy1WTIpSx9YwFFD\n",
        "! unzip /content/FORGe_colab_v3_WebNLG.zip\n",
        "# Version used for Mod-D2T (minor improvements on WebNLG)\n",
        "# ! gdown 196w_EtORTkR3idaXDMq0xl3pOtBrGbiE\n",
        "# ! unzip /content/FORGe_colab_v4.zip\n",
        "\n",
        "# Download Morphology generator\n",
        "! gdown 1vk1utEjeZ_2YO1H20DPDTjVSevgRJNM_\n",
        "morph_folder_name = 'test_irish_morph_gen_v5.0'\n",
        "zip_name = morph_folder_name+'.zip'\n",
        "! unzip {zip_name}\n",
        "\n",
        "morph_input_folder = '/content/'+morph_folder_name+'/Inputs'\n",
        "morph_output_folder = '/content/'+morph_folder_name+'/Outputs'\n",
        "os.makedirs(morph_input_folder)\n",
        "os.makedirs(morph_output_folder)\n",
        "\n",
        "# Make morphology flookup executable\n",
        "! 7z a -sfx {morph_folder_name}'/flookup.exe' {morph_folder_name}'/flookup'\n",
        "! chmod 755 {morph_folder_name}'/flookup'\n",
        "\n",
        "# Clean\n",
        "! rm '/content/FORGe_colab_v3_WebNLG.zip'\n",
        "! rm '/content/FORGe_colab_v4.zip'\n",
        "! rm '/content/test_irish_morph_gen_v5.0.zip'\n",
        "clear_output()\n",
        "print('Working folder ready!\\n--------------\\nInstalling Java 8...\\n')\n",
        "\n",
        "# Switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZrDTZNaPWkP"
      },
      "outputs": [],
      "source": [
        "# Run this cell to set parameters for generation\n",
        "\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "# E.g. if one a module PredArg_... or DSynt_... is selected, the input predicate-argument structures should be placed in the structures/00-PredArg folder\n",
        "# I'll make the instructions and names clearer in a later (actually usable) version.\n",
        "\n",
        "############# Select language #############\n",
        "language = 'GA' #@param['EN', 'ES', 'GA']\n",
        "\n",
        "############# Select module grouping #############\n",
        "# Group consecutive modules for the same system or call each module separately.\n",
        "# Select 'no' to get all intermediate representations, 'yes' if you're only interested in the output.\n",
        "group_modules_prm = 'yes' #@param['yes', 'no']\n",
        "\n",
        "############# Select dataset split #############\n",
        "split = \"test\" #@param['dev', 'test','train','ukn']\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "# To have an external module assigning triples to aggregate\n",
        "PredArg_AggregationMark = 'None'\n",
        "PredArg_Aggregation = 'FORGe'\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe'\n",
        "RE_Generation = 'FORGe'\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "SMorph_Processing = 'FORGe'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to python files\n",
        "path_MFleNS = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS.py'\n",
        "path_checkOutputs = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS-checkOutputs.py'\n",
        "path_postProc = '/content/M-FleNS_NLG-Pipeline/code/postProcess.py'\n",
        "path_FORGe2Morph = '/content/DCU_TCD-FORGe_WebNLG23/code/FORGe2Morph.py'\n",
        "# path_MorphGen = '/content/DCU_TCD-FORGe_WebNLG23/code/IrishNLP_MorphGen.py'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = '/content/FORGe/buddy_project/struct'\n",
        "path_MATE = '/content/FORGe/buddy-patched.jar'\n",
        "path_props_resources_template = '/content/FORGe/mateColabDrive.properties'\n",
        "path_props_levels = '/content/FORGe/mateLevels.properties'\n",
        "path_props = '/content/FORGe/mate.properties'\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "path_strs = '/content/FORGe/structures'\n",
        "str_PredArg_folder = os.path.join(path_strs, '00-PredArg')\n",
        "str_PredArgNorm_folder = os.path.join(path_strs, '01-PredArgNorm')\n",
        "str_PredArgAggMark_folder = os.path.join(path_strs, '02-PredArgAggMark')\n",
        "str_PredArgAgg_folder = os.path.join(path_strs, '03-PredArgAgg')\n",
        "str_PredArgPoS_folder = os.path.join(path_strs, '04-PredArgPoS')\n",
        "str_PredArgComm_folder = os.path.join(path_strs, '05-PredArgComm')\n",
        "str_DSynt_folder = os.path.join(path_strs, '06-DSynt')\n",
        "str_SSynt_folder = os.path.join(path_strs, '07-SSynt')\n",
        "str_SSyntAgg_folder = os.path.join(path_strs, '08-SSyntAgg')\n",
        "str_REG_folder = os.path.join(path_strs, '09-REG')\n",
        "str_DMorphLin_folder = os.path.join(path_strs, '10-DMorphLin')\n",
        "str_SMorphText_folder = os.path.join(path_strs, '11-SMorphText')\n",
        "log_folder = '/content/FORGe/log'\n",
        "if not os.path.exists(log_folder):\n",
        "  os.makedirs(log_folder)\n",
        "temp_input_folder_morph = '/content/FORGe-out'\n",
        "if not os.path.exists(temp_input_folder_morph):\n",
        "  os.makedirs(temp_input_folder_morph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9-g7wFiLYe"
      },
      "source": [
        "# Run generation pipeline\n",
        "\n",
        "Run all cells to get the concatenated texts, intermediate representations and log files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPOmwVKtnp0"
      },
      "source": [
        "## 1 - RDF to PredArg (TBD)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the moment, you can download the outputs of the conversion and copy the desired inputs of the same split in the str_PredArg_folder (see below).\n",
        "! gdown 1B_8UXCiC71hqqiBhcgTQ1Jg_6Y-Nc5su\n",
        "! unzip /content/00-PredArg-train.zip\n",
        "! rm '/content/00-PredArg-train.zip'\n",
        "\n",
        "! gdown 1YXcDXNS8lnU9EWBbVpYtHIJFQLHqAg0w\n",
        "! unzip /content/00-PredArg-test.zip\n",
        "! rm '/content/00-PredArg-test.zip'\n",
        "\n",
        "! gdown 1L0D3pyUW43qep5C2jvmbdQyzbZesMFOb\n",
        "! unzip /content/00-PredArg-dev.zip\n",
        "! rm '/content/00-PredArg-dev.zip'\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "8ua2sUZOfshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy some PredArg structures in the input folder used for generation\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "predArg_conv_folder = '/content/00-PredArg-'+split\n",
        "# predArg_conv_folder = '/content/00-PredArg-dev'\n",
        "# predArg_conv_folder = '/content/00-PredArg-test'\n",
        "# predArg_conv_folder = '/content/00-PredArg-train'\n",
        "list_predArgPaths = glob.glob(os.path.join(predArg_conv_folder, '*.conll'))\n",
        "c = 0\n",
        "for predArgPath in list_predArgPaths:\n",
        "  PAfilename = os.path.split(predArgPath)[-1]\n",
        "  ! cp {predArgPath} '/content/FORGe/structures/00-PredArg/'{PAfilename}\n",
        "  c += 1\n",
        "print('Copied '+str(c)+' files.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oJ8takwf5RV",
        "outputId": "c7395a90-a56e-4cfd-e87b-f7c7a9bf95d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 4 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty input folder to copy other inputs instead\n",
        "# list_predArgPathsCC = glob.glob(os.path.join('/content/FORGe/structures/00-PredArg/', '*.conll'))\n",
        "# c = 0\n",
        "# for predArgPathCC in list_predArgPathsCC:\n",
        "#   ! rm {predArgPathCC}\n",
        "#   c += 1\n",
        "# print('Removed '+str(c)+' files.')"
      ],
      "metadata": {
        "id": "lajIWwJHf8Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0l_N2UGtrNx"
      },
      "source": [
        "## 2 - PredArg to uninflected text (FORGe via M-FleNS pipeline code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch generation process\n",
        "! python {path_MFleNS} {language} {split} {group_modules_prm} {PredArg_Normalisation} {PredArg_AggregationMark} {PredArg_Aggregation} {PredArg_PoSTagging} {PredArg_CommStructuring} {DSynt_Structuring} {SSynt_Structuring} {SSynt_Aggregation} {RE_Generation} {DMorph_AgreementsLinearisation} {SMorph_Processing} {FORGe_input_folder} {path_MATE} {path_props_resources_template} {path_props_levels} {path_props} {str_PredArg_folder} {str_PredArgNorm_folder} {str_PredArgAggMark_folder} {str_PredArgAgg_folder} {str_PredArgPoS_folder} {str_PredArgComm_folder} {str_DSynt_folder} {str_SSynt_folder} {str_SSyntAgg_folder} {str_REG_folder} {str_DMorphLin_folder} {str_SMorphText_folder} {log_folder}\n"
      ],
      "metadata": {
        "id": "q_DsIRYArBq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5194117b-0f23-4325-9912-7210c89c7a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing generation pipeline...\n",
            "  -> Initial structure is ['PredArg'].\n",
            "  -> 10 modules were selected.\n",
            "  -> Sequence: ['PredArgNorm', 'PredArgAgg', 'PredArgPoS', 'PredArgComm', 'DSynt', 'SSynt', 'SSyntAgg', 'REG', 'DMorphLin', 'SMorphText']\n",
            "  -> The pipeline looks good, proceeding...\n",
            "--------------------------\n",
            "Running FORGe\n",
            "--------------------------\n",
            "  Running ['10_Con_Sem.rl', '11.1_Con_Agg1.rl', '11.2_Con_Agg2.rl', '11.3_Con_Agg3.rl', '11.4_Con_Agg4.rl', '13_Sem_SemPoS.rl', '15_SemPoS_SemCommMark.rl', '17_SemCommMark_SemComm.rl', '20_SemComm_DSynt.rl', '30_DSynt_SSynt.rl', '35_SSynt_PostProc.rl', '37.1_SSynt_Agg1.rl', '37.2_SSynt_Agg2.rl', '38.1_SSynt_REG1.rl', '38.2_SSynt_REG2.rl', '40_SSynt_DMorph_linearize.rl', '50_DMorph_SMorph.rl', '60_Smorph_Sentence.rl']\n",
            "=================================================\n",
            "All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check outputs and copy files to morph folder if GA\n",
        "import codecs\n",
        "\n",
        "## Read original check script\n",
        "#check_script = open(path_checkOutputs, 'r')\n",
        "#lines_check_script = check_script.readlines()\n",
        "## Update check script\n",
        "#with codecs.open(path_checkOutputs, 'w', 'utf-8') as f:\n",
        "#  for line in lines_check_script:\n",
        "#    if line.startswith('log_folder = sys.argv[3]'):\n",
        "#      f.write('log_folder = sys.argv[3]\\ntemp_input_folder_morph = sys.argv[4]\\nlanguage = sys.argv[5]\\n')\n",
        "#    elif line.startswith('            count_perLevel.append(count)\\n'):\n",
        "#      f.write('            count_perLevel.append(count)\\n            if language == \"GA\":\\n              shutil.copy(new_file_path, temp_input_folder_morph)\\n')\n",
        "#    else:\n",
        "#      f.write(line)\n",
        "\n",
        "! python {path_checkOutputs} {str_PredArg_folder} {str_SMorphText_folder} {log_folder} {temp_input_folder_morph} {language}"
      ],
      "metadata": {
        "id": "jzXG50NysYe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9364ec78-17e8-461c-a98e-e84cdcace053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log files OK!\n",
            "----\n",
            "\n",
            "\n",
            "Number of texts OK!\n",
            "----\n",
            "Inputs:  1779\n",
            "Outputs: 1779\n",
            "Inputs per file:  [450, 450, 450, 429]\n",
            "Outputs per file: [450, 450, 450, 429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iPz_wQhte3q"
      },
      "source": [
        "## 3 - Morphology processing (Irish NLP Tools)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process raw FORGe output and format it for Morphology\n",
        "\n",
        "# Read original check script\n",
        "FORGe_log = open('/content/FORGe/log/summary.txt', 'r')\n",
        "lines_log = FORGe_log.readlines()\n",
        "# Get number of expected texts\n",
        "count_strs_all_FORGe = 0\n",
        "for line in lines_log:\n",
        "  if line.startswith('Outputs: '):\n",
        "    count_strs_all_FORGe = int(line.strip().split('Outputs: ')[-1])\n",
        "\n",
        "print('Expected texts: '+str(count_strs_all_FORGe)+'.\\n')\n",
        "\n",
        "! python {path_FORGe2Morph} {language} {temp_input_folder_morph} {morph_input_folder}"
      ],
      "metadata": {
        "id": "8TFQOgvG0laB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54cf986d-b4c9-4392-e8ad-ca9279d15c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected texts: 1779.\n",
            "\n",
            "Processing test_triples_en_ga_utf8_0000-0449__SMorphText.conll_out.txt\n",
            "Processing test_triples_en_ga_utf8_0450-0899__SMorphText.conll_out.txt\n",
            "Processing test_triples_en_ga_utf8_0900-1349__SMorphText.conll_out.txt\n",
            "Processing test_triples_en_ga_utf8_1350-1778__SMorphText.conll_out.txt\n",
            "\n",
            "There are 1779 texts.\n",
            "Texts per file: [450, 450, 450, 429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "uPBqNqjkueAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b38f1c-8cde-4423-b407-bcfdf7b88cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test_triples_en_ga_utf8_0000-0449__SMorphText\n",
            "Processing test_triples_en_ga_utf8_0450-0899__SMorphText\n",
            "Processing test_triples_en_ga_utf8_0900-1349__SMorphText\n",
            "Processing test_triples_en_ga_utf8_1350-1778__SMorphText\n",
            "\n",
            "There are 1779 texts.\n",
            "Texts per file: [450, 450, 450, 429]\n"
          ]
        }
      ],
      "source": [
        "# Call morph generator\n",
        "# v3 (fast, ~2sec/450 texts)\n",
        "\n",
        "# Run the morphology generation\n",
        "from IPython.display import HTML, display\n",
        "import progressbar\n",
        "import glob\n",
        "import codecs\n",
        "from termcolor import colored\n",
        "import re\n",
        "\n",
        "show_input = False #@param {type:\"boolean\"}\n",
        "\n",
        "if language == 'GA':\n",
        "# To store how many texts we have in each file (used to )\n",
        "  count_strs_all_Morph = []\n",
        "  for filepath in sorted(glob.glob(os.path.join(morph_input_folder, '*.*'))):\n",
        "    count_strs_all = 0\n",
        "    head, tail = os.path.split(filepath)\n",
        "    filename = tail.rsplit('.')[0]\n",
        "    print('Processing '+filename)\n",
        "    fo = codecs.open(morph_output_folder+'/'+filename+'_out.txt', 'w', 'utf-8')\n",
        "    list_inflected_words = ! cat {filepath} | {morph_folder_name}'/flookup' -a {morph_folder_name}'/allgen.fst'\n",
        "    # print(list_inflected_words)\n",
        "\n",
        "    # Create a variable to store the outputs\n",
        "    text = ''\n",
        "    # morph returns this as list_inflected_words: ['imir+Verb+Vow+PresInd\\timríonn', '', 'Agremiação_Sportiva_Arapiraquense+Noun+Masc+Com+Pl\\t+?', '', ',\\t+?',...]\n",
        "    for word in list_inflected_words:\n",
        "      empty = 'yes'\n",
        "      input_string = ''\n",
        "      morph_returned = ''\n",
        "      morph_backup = ''\n",
        "      if re.search('\\t', word):\n",
        "        # for every space an empty string is returned; we'll ignore them later. Between two consecutive texts there is a simple \"\\t\" with nothing around. I use this to introduce linebreaks later.\n",
        "        empty = 'no'\n",
        "        input_string = word.split('\\t')[0]\n",
        "        morph_returned = word.split('\\t')[1]\n",
        "        if re.search('\\+', word):\n",
        "          morph_backup = input_string.split('+', 1)[0]\n",
        "        else:\n",
        "          morph_backup = input_string\n",
        "      out_line = ''\n",
        "      # Create each output line with the required contents\n",
        "      if show_input == True:\n",
        "        if empty == 'no':\n",
        "          if morph_returned == '':\n",
        "            if input_string == '':\n",
        "              out_line = out_line + '\\n'\n",
        "              count_strs_all += 1\n",
        "          else:\n",
        "            out_line = out_line + input_string + ': ' +'\\x1b[5;30;47m'+morph_returned+'\\x1b[0m'+'\\n'\n",
        "      else:\n",
        "        if empty == 'no':\n",
        "          if morph_returned == '+?':\n",
        "            out_line = out_line + morph_backup + ' '\n",
        "          # If the line is empty, add a line break (empty lines separate different texts in the input)\n",
        "          elif morph_returned == '':\n",
        "            if input_string == '':\n",
        "              out_line = out_line + '\\n'\n",
        "              count_strs_all += 1\n",
        "          else:\n",
        "            out_line = out_line + morph_returned + ' '\n",
        "      # add line to the other lines of the same file\n",
        "      text = text + out_line\n",
        "\n",
        "    # print('\\n----------------------\\n'+text+'\\n')\n",
        "    count_strs_all_Morph.append(count_strs_all)\n",
        "    fo.write(text+'\\n')\n",
        "    fo.close()\n",
        "\n",
        "  # Check\n",
        "  with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "    fo.write('\\nMorphology debug\\n==================\\n\\n')\n",
        "    if not sum(count_strs_all_Morph) == count_strs_all_FORGe:\n",
        "      print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "      fo.write('ERROR! Mismatch with FORGe outputs!\\n')\n",
        "    print('\\nThere are '+str(sum(count_strs_all_Morph))+' texts.')\n",
        "    fo.write('There are '+str(sum(count_strs_all_Morph))+' texts.\\n')\n",
        "    print('Texts per file: '+str(count_strs_all_Morph))\n",
        "    fo.write('Texts per file: '+str(count_strs_all_Morph)+'\\n')\n",
        "    fo.write('---------------------------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsBqWCAuxyE"
      },
      "source": [
        "## 4 - Output post-processing and packaging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process texts\n",
        "prefinal_output_folder = ''\n",
        "\n",
        "if language == 'GA':\n",
        "  prefinal_output_folder = morph_output_folder\n",
        "else:\n",
        "  prefinal_output_folder = temp_input_folder_morph\n",
        "\n",
        "! python {path_postProc} {language} {prefinal_output_folder}\n",
        "\n",
        "# Check\n",
        "list_filepaths = glob.glob(os.path.join(prefinal_output_folder, '*_postproc.txt'))\n",
        "count_strs_all_postproc = []\n",
        "for filepath in sorted(list_filepaths):\n",
        "  count_strs_all = 0\n",
        "  head, tail = os.path.split(filepath)\n",
        "  fd = codecs.open(filepath, 'r', 'utf-8')\n",
        "  lines = fd.readlines()\n",
        "  x = 0\n",
        "  for line in lines:\n",
        "    if not line == '\\n':\n",
        "      count_strs_all += 1\n",
        "    x += 1\n",
        "  count_strs_all_postproc.append(count_strs_all)\n",
        "\n",
        "with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "  fo.write('\\nPost-processing debug\\n==================\\n\\n')\n",
        "  if not sum(count_strs_all_postproc) == count_strs_all_FORGe:\n",
        "    print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "    fo.write('ERROR! Mismatch with FORGe outputs!\\n')\n",
        "  print('\\nThere are '+str(sum(count_strs_all_postproc))+' texts.')\n",
        "  fo.write('There are '+str(sum(count_strs_all_postproc))+' texts.\\n')\n",
        "  print('Texts per file: '+str(count_strs_all_postproc))\n",
        "  fo.write('Texts per file: '+str(count_strs_all_postproc)+'\\n')\n",
        "  fo.write('---------------------------------\\n')"
      ],
      "metadata": {
        "id": "ODAI93StJjVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4397c8a0-4fcb-49e7-ddac-e6c49c65f17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test_triples_en_ga_utf8_0000-0449__SMorphText_out\n",
            "Processing test_triples_en_ga_utf8_0450-0899__SMorphText_out\n",
            "Processing test_triples_en_ga_utf8_0900-1349__SMorphText_out\n",
            "Processing test_triples_en_ga_utf8_1350-1778__SMorphText_out\n",
            "\n",
            "There are 1779 texts.\n",
            "Texts per file: [450, 450, 450, 429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfQ08wHOu8eZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c7e661-b4ee-41f6-9ce3-518816486b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/test_irish_morph_gen_v5.0/Outputs/test_triples_en_ga_utf8_0000-0449__SMorphText_out_postproc.txt\n",
            "Processing /content/test_irish_morph_gen_v5.0/Outputs/test_triples_en_ga_utf8_0450-0899__SMorphText_out_postproc.txt\n",
            "Processing /content/test_irish_morph_gen_v5.0/Outputs/test_triples_en_ga_utf8_0900-1349__SMorphText_out_postproc.txt\n",
            "Processing /content/test_irish_morph_gen_v5.0/Outputs/test_triples_en_ga_utf8_1350-1778__SMorphText_out_postproc.txt\n",
            "\n",
            "There are 1779 texts.\n"
          ]
        }
      ],
      "source": [
        "# Concatenate files\n",
        "\n",
        "list_clean_outputs = glob.glob(os.path.join(morph_output_folder, '*_out_postproc.txt'))\n",
        "filename = 'all_'+language+'_'+split+'_out.txt'\n",
        "\n",
        "with codecs.open(filename, 'w', 'utf-8') as outfile:\n",
        "  # Files need to be sorted to be concatenated in the right order\n",
        "  for fname in sorted(list_clean_outputs):\n",
        "    print('Processing '+fname)\n",
        "    with open(fname) as infile:\n",
        "      outfile.write(infile.read())\n",
        "\n",
        "# Check\n",
        "with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "  fo.write('\\nConcatenate debug\\n==================\\n\\n')\n",
        "  count_texts_all = len(codecs.open(filename).readlines())\n",
        "  if not count_texts_all == count_strs_all_FORGe:\n",
        "    print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "    fo.Write(('ERROR! Mismatch with FORGe outputs!\\n'))\n",
        "  print('\\nThere are '+str(count_texts_all)+' texts.')\n",
        "  fo.write('There are '+str(count_texts_all)+' texts.\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip and download FORGE output folder to download intermediate representations\n",
        "from google.colab import files\n",
        "zip_name_inter = '/content/WebNLG_['+language+']_['+split+']_allLevels.zip'\n",
        "!zip -r {zip_name_inter} /content/FORGe/structures\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_inter)\n",
        "# print('Donwloaded intermediate representations!')\n",
        "# ! rm {zip_name_inter}"
      ],
      "metadata": {
        "id": "kRClGzfcJ5Nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "546db6ed-b236-4e50-c863-7556fa94713c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e706721a-5b2b-40fc-a95f-51e4615c8624\", \"WebNLG_[GA]_[test]_allLevels.zip\", 9654505)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_yzCQGBshN1"
      },
      "outputs": [],
      "source": [
        "# Zip FORGe log files folder\n",
        "from google.colab import files\n",
        "zip_name_log = '/content/WebNLG_['+language+']_['+split+']_logs.zip'\n",
        "!zip -r {zip_name_log} /content/FORGe/log\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_log)\n",
        "# print('Donwloaded log files!')\n",
        "# ! rm {zip_name_log}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9o9BWi1KV4Iwd5RKB0G7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
