{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/DCU_TCD-FORGe_WebNLG23/blob/main/DCU_TCD_FORGe_WebNLG23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1EixVIRHmxqi"
      },
      "outputs": [],
      "source": [
        "# @title Prepare repo\n",
        "\n",
        "# Run this cell to download and unzip the working folder and install Java 8\n",
        "\n",
        "from IPython.display import clear_output, HTML, display\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# clone main repo\n",
        "! git clone https://github.com/mille-s/DCU_TCD-FORGe_WebNLG23.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'DCU_TCD-FORGe_WebNLG23/DCU_TCD_FORGe_WebNLG23.ipynb'\n",
        "\n",
        "# clone M-FleNS repo (generation pipeline)\n",
        "! git clone https://github.com/mille-s/M-FleNS_NLG-Pipeline.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'M-FleNS_NLG-Pipeline/M_FleNS_pipe_v2.ipynb'\n",
        "\n",
        "# Download FORGe\n",
        "# Version used for WebNLG (fails to generate a few structures of the training data)\n",
        "# ! gdown 1lsh8pwUp9mc0Z_aFbSy1WTIpSx9YwFFD\n",
        "# ! unzip /content/FORGe_colab_v3_WebNLG.zip\n",
        "# Version used for Mod-D2T (minor improvements on WebNLG)\n",
        "! gdown 196w_EtORTkR3idaXDMq0xl3pOtBrGbiE\n",
        "! unzip /content/FORGe_colab_v4.zip\n",
        "\n",
        "# Download triple to predArg conversion\n",
        "triple2predArg = 'triples2predArg'\n",
        "os.makedirs(triple2predArg)\n",
        "! gdown 1Fr_ThZHGPLkoi3XQthSsaM5uVGLxgVat\n",
        "! unzip 'triples2predArg2.zip' -d {triple2predArg}\n",
        "! rm 'triples2predArg2.zip'\n",
        "\n",
        "# Download Morphology generator\n",
        "! gdown 1vk1utEjeZ_2YO1H20DPDTjVSevgRJNM_\n",
        "morph_folder_name = 'test_irish_morph_gen_v5.0'\n",
        "zip_name = morph_folder_name+'.zip'\n",
        "! unzip {zip_name}\n",
        "\n",
        "morph_input_folder = '/content/'+morph_folder_name+'/Inputs'\n",
        "morph_output_folder = '/content/'+morph_folder_name+'/Outputs'\n",
        "os.makedirs(morph_input_folder)\n",
        "os.makedirs(morph_output_folder)\n",
        "\n",
        "# Make morphology flookup executable\n",
        "! 7z a -sfx {morph_folder_name}'/flookup.exe' {morph_folder_name}'/flookup'\n",
        "! chmod 755 {morph_folder_name}'/flookup'\n",
        "\n",
        "# Package for parsing XML files\n",
        "!pip install xmltodict\n",
        "# Install SPARQLWrapper\n",
        "! pip install SPARQLWrapper\n",
        "\n",
        "# Clean\n",
        "! rm '/content/FORGe_colab_v3_WebNLG.zip'\n",
        "! rm '/content/FORGe_colab_v4.zip'\n",
        "! rm '/content/test_irish_morph_gen_v5.0.zip'\n",
        "clear_output()\n",
        "print('Working folder ready!\\n--------------\\nInstalling Java 8...\\n')\n",
        "\n",
        "# Switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()\n",
        "\n",
        "# To wrap texts in cells\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sZrDTZNaPWkP"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters, create empty folders\n",
        "\n",
        "# Run this cell to set parameters for generation\n",
        "\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "# E.g. if one a module PredArg_... or DSynt_... is selected, the input predicate-argument structures should be placed in the structures/00-PredArg folder\n",
        "# I'll make the instructions and names clearer in a later (actually usable) version.\n",
        "\n",
        "############# Select language #############\n",
        "language = 'GA' #@param['EN', 'GA']\n",
        "\n",
        "############# Choose whether or not to look for class and gender information of entities via DBpedia #############\n",
        "# Not implemented yet, right now it concatenates the files whatever happens\n",
        "get_class_gender = 'no' #@param['yes', 'no']\n",
        "\n",
        "############# Choose whether or not to concatenate output files #############\n",
        "# Not implemented yet, right now it concatenates the files whatever happens\n",
        "concatenate_output_files = 'yes' #@param['yes', 'no']\n",
        "\n",
        "############# Select module grouping #############\n",
        "# Group consecutive modules for the same system or call each module separately.\n",
        "# Select 'no' to get all intermediate representations, 'yes' if you're only interested in the output.\n",
        "generate_intermediate_representations = 'no' #@param['yes', 'no']\n",
        "group_modules_prm = ''\n",
        "if generate_intermediate_representations == 'yes':\n",
        "  group_modules_prm = 'no'\n",
        "else:\n",
        "  group_modules_prm = 'yes'\n",
        "\n",
        "############# Select dataset split #############\n",
        "split = \"dev\" #@param['dev', 'test','train','ukn']\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "# To have an external module assigning triples to aggregate\n",
        "PredArg_AggregationMark = 'None'\n",
        "PredArg_Aggregation = 'FORGe'\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe'\n",
        "RE_Generation = 'FORGe'\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "SMorph_Processing = 'FORGe'\n",
        "\n",
        "# # Tests Lin only (also modify M-FleNS.py)\n",
        "# PredArg_Normalisation = 'None'\n",
        "# PredArg_AggregationMark = 'None'\n",
        "# PredArg_Aggregation = 'None'\n",
        "# PredArg_PoSTagging = 'None'\n",
        "# PredArg_CommStructuring = 'None'\n",
        "# DSynt_Structuring = 'None'\n",
        "# SSynt_Structuring = 'None'\n",
        "# SSynt_Aggregation = 'None'\n",
        "# RE_Generation = 'None'\n",
        "# DMorph_AgreementsLinearisation = 'FORGe'\n",
        "# SMorph_Processing = 'FORGe'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to python files\n",
        "path_MFleNS = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS.py'\n",
        "path_checkOutputs = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS-checkOutputs.py'\n",
        "path_postProc = '/content/M-FleNS_NLG-Pipeline/code/postProcess.py'\n",
        "path_FORGe2Morph = '/content/DCU_TCD-FORGe_WebNLG23/code/FORGe2Morph.py'\n",
        "path_concatenate = '/content/M-FleNS_NLG-Pipeline/code/concatenate_files.py'\n",
        "path_getClassGenderDBp = '/content/M-FleNS_NLG-Pipeline/code/getClassGenderDBpedia.py'\n",
        "path_splitFiles = '/content/M-FleNS_NLG-Pipeline/code/splitFiles.py'\n",
        "# path_MorphGen = '/content/DCU_TCD-FORGe_WebNLG23/code/IrishNLP_MorphGen.py'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = '/content/FORGe/buddy_project/struct'\n",
        "path_MATE = '/content/FORGe/buddy-patched.jar'\n",
        "path_props_resources_template = '/content/FORGe/mateColabDrive.properties'\n",
        "path_props_levels = '/content/FORGe/mateLevels.properties'\n",
        "path_props = '/content/FORGe/mate.properties'\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "path_strs = '/content/FORGe/structures'\n",
        "path_input_XML = '/content/input_XMLs'\n",
        "str_PredArg_folder = os.path.join(path_strs, '00-PredArg')\n",
        "str_PredArgNorm_folder = os.path.join(path_strs, '01-PredArgNorm')\n",
        "str_PredArgAggMark_folder = os.path.join(path_strs, '02-PredArgAggMark')\n",
        "str_PredArgAgg_folder = os.path.join(path_strs, '03-PredArgAgg')\n",
        "str_PredArgPoS_folder = os.path.join(path_strs, '04-PredArgPoS')\n",
        "str_PredArgComm_folder = os.path.join(path_strs, '05-PredArgComm')\n",
        "str_DSynt_folder = os.path.join(path_strs, '06-DSynt')\n",
        "str_SSynt_folder = os.path.join(path_strs, '07-SSynt')\n",
        "str_SSyntAgg_folder = os.path.join(path_strs, '08-SSyntAgg')\n",
        "str_REG_folder = os.path.join(path_strs, '09-REG')\n",
        "str_DMorphLin_folder = os.path.join(path_strs, '10-DMorphLin')\n",
        "str_SMorphText_folder = os.path.join(path_strs, '11-SMorphText')\n",
        "log_folder = '/content/FORGe/log'\n",
        "\n",
        "if not os.path.exists(log_folder):\n",
        "  os.makedirs(log_folder)\n",
        "if not os.path.exists(path_input_XML):\n",
        "  os.makedirs(path_input_XML)\n",
        "temp_input_folder_morph = '/content/FORGe-out'\n",
        "if not os.path.exists(temp_input_folder_morph):\n",
        "  os.makedirs(temp_input_folder_morph)\n",
        "\n",
        "def clear_files(folder):\n",
        "  \"Function to clear files from a folder.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "          os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "          shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "def clear_folder(folder):\n",
        "  \"Function to clear whole folders.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    try:\n",
        "      shutil.rmtree(folder)\n",
        "    except Exception as e:\n",
        "      print('Failed to delete %s. Reason: %s' % (folder, e))\n",
        "\n",
        "def removeReservedCharsFileName(entityName):\n",
        "  # reservedChars = ['#', '%', '&', '\\{', '\\}', '\\\\', '<', '>', '\\*', '\\?', '/', ' ', '\\$', '!', \"'\", '\"', ':', '@', '\\+', '`', '\\|', '=']\n",
        "  newEntityName = str(entityName)\n",
        "  # for reservedChar in reservedChars:\n",
        "  while re.search(r'[#%&\\{\\}\\\\<>\\*\\?/ \\$!\\'\":@\\+`\\|=]', newEntityName):\n",
        "    newEntityName = re.sub(r'[#%&\\{\\}\\\\<>\\*\\?/ \\$!\\'\":@\\+`\\|=]', \"\", newEntityName)\n",
        "  return(newEntityName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9-g7wFiLYe"
      },
      "source": [
        "# Run generation pipeline\n",
        "\n",
        "Run all cells to get the concatenated texts, intermediate representations and log files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPOmwVKtnp0"
      },
      "source": [
        "## 1 (Alternative 1) - RDF to PredArg (Using pre-generated WebNLG files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ua2sUZOfshs"
      },
      "outputs": [],
      "source": [
        "# For the moment, you can download the outputs of the conversion and copy the desired inputs of the same split in the str_PredArg_folder (see below).\n",
        "! gdown 1B_8UXCiC71hqqiBhcgTQ1Jg_6Y-Nc5su\n",
        "! unzip /content/00-PredArg-train.zip\n",
        "! rm '/content/00-PredArg-train.zip'\n",
        "\n",
        "! gdown 1YXcDXNS8lnU9EWBbVpYtHIJFQLHqAg0w\n",
        "! unzip /content/00-PredArg-test.zip\n",
        "! rm '/content/00-PredArg-test.zip'\n",
        "\n",
        "! gdown 1L0D3pyUW43qep5C2jvmbdQyzbZesMFOb\n",
        "! unzip /content/00-PredArg-dev.zip\n",
        "! rm '/content/00-PredArg-dev.zip'\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4oJ8takwf5RV",
        "outputId": "a59f75f3-79d3-4fe6-9846-6c4e3d924d43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied 4 files.\n"
          ]
        }
      ],
      "source": [
        "# Copy some PredArg structures in the input folder used for generation\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# empty FORGe input folder\n",
        "clear_files(str_PredArg_folder)\n",
        "\n",
        "predArg_conv_folder = '/content/00-PredArg-'+split\n",
        "# predArg_conv_folder = '/content/00-PredArg-dev'\n",
        "# predArg_conv_folder = '/content/00-PredArg-test'\n",
        "# predArg_conv_folder = '/content/00-PredArg-train'\n",
        "list_predArgPaths = glob.glob(os.path.join(predArg_conv_folder, '*.conll'))\n",
        "c = 0\n",
        "for predArgPath in list_predArgPaths:\n",
        "  PAfilename = os.path.split(predArgPath)[-1]\n",
        "  ! cp {predArgPath} '/content/FORGe/structures/00-PredArg/'{PAfilename}\n",
        "  c += 1\n",
        "print('Copied '+str(c)+' files.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lajIWwJHf8Km",
        "outputId": "b225c017-e733-4dd5-e8a4-50d41175cb27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Empty input folder to copy other inputs instead\n",
        "# list_predArgPathsCC = glob.glob(os.path.join('/content/FORGe/structures/00-PredArg/', '*.conll'))\n",
        "# c = 0\n",
        "# for predArgPathCC in list_predArgPathsCC:\n",
        "#   ! rm {predArgPathCC}\n",
        "#   c += 1\n",
        "# print('Removed '+str(c)+' files.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYliSyNnOUCK"
      },
      "source": [
        "## 1 (Alternative 2) - RDF to PredArg (Using XML files in the WebNLG format that you upload in the input_XMLs folder on the left.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjRlUk3JnntV"
      },
      "outputs": [],
      "source": [
        "# Pre-processing of input XMls\n",
        "import codecs\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "\n",
        "list_XML_files = glob.glob(os.path.join(path_input_XML, '*.xml'))\n",
        "\n",
        "months_map = {'January':'01', 'February': '02', 'March': '03', 'April': '04', 'May': '05', 'June': '06', 'July': '07', 'August': '08', 'September': '09', 'October': '10', 'November': '11', 'December': '12' }\n",
        "months_list = list(months_map.keys())\n",
        "for XML_file_path in list_XML_files:\n",
        "  print(XML_file_path)\n",
        "  xml_file = codecs.open(XML_file_path, 'r', 'utf-8').readlines()\n",
        "  count_matches = 0\n",
        "  with codecs.open(XML_file_path, 'w', 'utf-8') as fo:\n",
        "    for line in xml_file:\n",
        "      new_line = line\n",
        "      # Reformat dates so they are tagged correctly by XML2PredArg conversion\n",
        "      for month in months_list:\n",
        "        if re.search(month+'_[0-9]_[0-9]{4}', line):\n",
        "          month_num = months_map[month]\n",
        "          new_line = re.subn(month+'_([0-9])_([0-9]{4})', '\\g<2>-'+month_num+'-0\\g<1>', line)[0]\n",
        "          count_matches += 1\n",
        "        elif re.search(month+'_[0-9]{2}_[0-9]{4}', line):\n",
        "          month_num = months_map[month]\n",
        "          new_line = re.subn(month+'_([0-9]{2})_([0-9]{4})', '\\g<2>-'+month_num+'-\\g<1>', line)[0]\n",
        "          count_matches += 1\n",
        "      # Remove the ID prefix to the IDs, breaks the XML2PredArg conversion\n",
        "      if re.search('eid=\"Id', line):\n",
        "        new_line = re.sub('eid=\"Id', 'eid=\"', line)\n",
        "      fo.write(new_line)\n",
        "  print('Replaced '+str(count_matches)+' lines.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3OyRIIjOx1Y"
      },
      "outputs": [],
      "source": [
        "# Get and write class and gender information\n",
        "import json\n",
        "import glob\n",
        "import xmltodict\n",
        "import shutil\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "def extractTripleElements(dataset, element, existing_list):\n",
        "  \"\"\" Returns a list of subjects, objects or properties extracted from triple sets\"\"\"\n",
        "  n = ''\n",
        "  if element == 'subject':\n",
        "    n = 0\n",
        "  elif element == 'property':\n",
        "    n = 1\n",
        "  elif element == 'object':\n",
        "    n = 2\n",
        "  else:\n",
        "    print('Error, the second argument of extractTripleElements must be \"subject\", \"property\" or \"object\".')\n",
        "  element_list = []\n",
        "  for entry in dataset:\n",
        "    for input_triple in entry:\n",
        "      # print(input_triple)\n",
        "      element_name = input_triple.split(' | ')[n]\n",
        "      # To filter out values that give SPARQL query errors\n",
        "      if not re.search('`', element_name) and not re.search('\"', element_name):\n",
        "        new_element_name = '_'.join(element_name.split(' '))\n",
        "        if new_element_name not in element_list:\n",
        "          if new_element_name not in existing_list:\n",
        "            element_list.append(new_element_name)\n",
        "          # else:\n",
        "          #   print(new_element_name+' was already seen in WebNLG dataset!')\n",
        "  return(element_list)\n",
        "\n",
        "if get_class_gender == 'yes':\n",
        "  # List that contains all unique new triples from the input files\n",
        "  triple_sets_list = []\n",
        "\n",
        "  # Fill triple_sets_list with triples extracted from the input XML\n",
        "  for XML_file_path in list_XML_files:\n",
        "    print('Reading '+XML_file_path+'...')\n",
        "    xml_file = open(XML_file_path, 'r').read()\n",
        "    XML_data = xmltodict.parse(xml_file)\n",
        "\n",
        "    for entry in XML_data['benchmark']['entries']['entry']:\n",
        "      mtriples_list = []\n",
        "      # Get modified triples\n",
        "      if isinstance(entry['modifiedtripleset']['mtriple'], list):\n",
        "        for mtriple in entry['modifiedtripleset']['mtriple']:\n",
        "          mtriples_list.append(mtriple)\n",
        "      else:\n",
        "        mtriples_list.append(entry['modifiedtripleset']['mtriple'])\n",
        "      triple_sets_list.append(mtriples_list)\n",
        "\n",
        "  path_covered_subj = '/content/triples2predArg/classMembership/all_subValues.txt'\n",
        "  path_covered_obj = '/content/triples2predArg/classMembership/all_objValues.txt'\n",
        "\n",
        "  covered_subj_list_raw = codecs.open(path_covered_subj, 'r', 'utf-8').readlines()\n",
        "  covered_obj_list_raw = codecs.open(path_covered_obj, 'r', 'utf-8').readlines()\n",
        "\n",
        "  covered_subj_list = []\n",
        "  covered_obj_list = []\n",
        "  for covered_subj in covered_subj_list_raw:\n",
        "    clean_subj = covered_subj.strip()\n",
        "    covered_subj_list.append(clean_subj)\n",
        "  for covered_obj in covered_obj_list_raw:\n",
        "    clean_obj = covered_obj.strip()\n",
        "    covered_obj_list.append(clean_obj)\n",
        "\n",
        "  # Convert lists of subjets and objects to JSON to pass them as argument\n",
        "  list_subj = sorted(extractTripleElements(triple_sets_list, 'subject', covered_subj_list))\n",
        "  list_obj = sorted(extractTripleElements(triple_sets_list, 'object', covered_obj_list))\n",
        "\n",
        "  json_subj = json.dumps(list_subj)\n",
        "  json_obj = json.dumps(list_obj)\n",
        "  filepath_subj = os.path.join('/content/triples2predArg/classMembership', 'new_subj_values.json')\n",
        "  filepath_obj = os.path.join('/content/triples2predArg/classMembership', 'new_obj_values.json')\n",
        "\n",
        "  with codecs.open(filepath_subj, 'w', 'utf-8') as fo1:\n",
        "    fo1.write(json_subj)\n",
        "  with codecs.open(filepath_obj, 'w', 'utf-8') as fo2:\n",
        "    fo2.write(json_obj)\n",
        "\n",
        "  ! python {path_getClassGenderDBp} {filepath_subj} {filepath_obj}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lVnZKzuPFhx"
      },
      "outputs": [],
      "source": [
        "# Create FORGe input file (conll format)\n",
        "import shutil\n",
        "\n",
        "# empty FORGe input folder\n",
        "clear_files(str_PredArg_folder)\n",
        "\n",
        "language_t2p = language.lower()\n",
        "path_t2p_out = os.path.join(triple2predArg, 'out/')\n",
        "clear_files(path_t2p_out)\n",
        "\n",
        "path_t2p_out_split = os.path.join(triple2predArg, 'out_split/')\n",
        "if not os.path.exists(path_t2p_out_split):\n",
        "  os.makedirs(path_t2p_out_split)\n",
        "else:\n",
        "  clear_files(path_t2p_out_split)\n",
        "\n",
        "name_conll_templates = ''\n",
        "\n",
        "if language == 'GA':\n",
        "  name_conll_templates = '221130_WebNLG23_GA.conll'\n",
        "else:\n",
        "  name_conll_templates = '230528-WebNLG23_EN.conll'\n",
        "\n",
        "# newEntityName = removeReservedCharsFileName(entity_name)\n",
        "\n",
        "for XML_file_path in list_XML_files:\n",
        "  inputFilename = XML_file_path.rsplit('/', 1)[1].rsplit('.', 1)[0]\n",
        "  # Copy input files to triples2predArg repo\n",
        "  shutil.copy(XML_file_path, os.path.join(triple2predArg, inputFilename)+'.xml')\n",
        "\n",
        "  # Convert xml into predArg\n",
        "  print('Converting '+inputFilename+' to PredArg...')\n",
        "  !java -jar '/content/triples2predArg/webNLG_triples2conll.jar' '/content/triples2predArg/' {name_conll_templates} '230528-WebNLG23_EN-GA_properties.txt' {path_t2p_out} {language_t2p} {inputFilename}  # -> \"log.txt\"\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  # File splitting: the generator cannot process files that are too big, so they need to be split. For regular-sized inputs, 450 inputs per file should do.\n",
        "  # Whether split or not, the output files will be copied in the folder in [5]\n",
        "  # Parameters:\n",
        "  # [1] path to input folder\n",
        "  # [2] encoding of input files\n",
        "  # [3] number of structures per file\n",
        "  # [4] split once ('first'), or every time the threshold in [3] is reached ('all')\n",
        "  # [5] path to temp folder used to store split files\n",
        "  ! python {path_splitFiles} {path_t2p_out} 'utf-8' 300 'all' {path_t2p_out_split}\n",
        "\n",
        "  # Copy conll file to FORGe input folder\n",
        "  #The following \"if\" is not needed but I keep it in case we don't use splitFiles in the future.\n",
        "  if len(os.listdir(path_t2p_out_split)) == 0:\n",
        "    shutil.copy(os.path.join(path_t2p_out, inputFilename+'_'+language_t2p+'.conll'), str_PredArg_folder)\n",
        "    print('Copied files from '+str(path_t2p_out))\n",
        "  else:\n",
        "    list_conll_files = glob.glob(os.path.join(path_t2p_out_split, '*.conll'))\n",
        "    for conll_file in list_conll_files:\n",
        "      # conllFilename = conll_file.rsplit('/', 1)[1].rsplit('.', 1)[0]\n",
        "      shutil.copy(conll_file, str_PredArg_folder)\n",
        "    print('Copied files from '+str(path_t2p_out_split))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0l_N2UGtrNx"
      },
      "source": [
        "## 2 - PredArg to uninflected text (FORGe via M-FleNS pipeline code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_DsIRYArBq8"
      },
      "outputs": [],
      "source": [
        "# Launch generation process\n",
        "# ! python '/content/M-FleNS_NLG-Pipeline/code/M-FleNS.py' {language} {split} {group_modules_prm} {PredArg_Normalisation} {PredArg_AggregationMark} {PredArg_Aggregation} {PredArg_PoSTagging} {PredArg_CommStructuring} {DSynt_Structuring} {SSynt_Structuring} {SSynt_Aggregation} {RE_Generation} {DMorph_AgreementsLinearisation} {SMorph_Processing} {FORGe_input_folder} {path_MATE} {path_props_resources_template} {path_props_levels} {path_props} {str_PredArg_folder} {str_PredArgNorm_folder} {str_PredArgAggMark_folder} {str_PredArgAgg_folder} {str_PredArgPoS_folder} {str_PredArgComm_folder} {str_DSynt_folder} {str_SSynt_folder} {str_SSyntAgg_folder} {str_REG_folder} {str_DMorphLin_folder} {str_SMorphText_folder} {log_folder}\n",
        "! python {path_MFleNS} {language} {split} {group_modules_prm} {PredArg_Normalisation} {PredArg_AggregationMark} {PredArg_Aggregation} {PredArg_PoSTagging} {PredArg_CommStructuring} {DSynt_Structuring} {SSynt_Structuring} {SSynt_Aggregation} {RE_Generation} {DMorph_AgreementsLinearisation} {SMorph_Processing} {FORGe_input_folder} {path_MATE} {path_props_resources_template} {path_props_levels} {path_props} {str_PredArg_folder} {str_PredArgNorm_folder} {str_PredArgAggMark_folder} {str_PredArgAgg_folder} {str_PredArgPoS_folder} {str_PredArgComm_folder} {str_DSynt_folder} {str_SSynt_folder} {str_SSyntAgg_folder} {str_REG_folder} {str_DMorphLin_folder} {str_SMorphText_folder} {log_folder}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzXG50NysYe8"
      },
      "outputs": [],
      "source": [
        "# Check outputs and copy files to morph folder if GA\n",
        "import codecs\n",
        "\n",
        "# # Read original check script\n",
        "# check_script = open(path_checkOutputs, 'r')\n",
        "# lines_check_script = check_script.readlines()\n",
        "# # Update check script\n",
        "# with codecs.open(path_checkOutputs, 'w', 'utf-8') as f:\n",
        "#   for line in lines_check_script:\n",
        "#     if line.startswith('log_folder = sys.argv[3]'):\n",
        "#       f.write('log_folder = sys.argv[3]\\ntemp_input_folder_morph = sys.argv[4]\\nlanguage = sys.argv[5]\\n')\n",
        "#     elif line.startswith('            count_perLevel.append(count)\\n'):\n",
        "#       f.write('            count_perLevel.append(count)\\n            if language == \"GA\":\\n              shutil.copy(new_file_path, temp_input_folder_morph)\\n')\n",
        "#     else:\n",
        "#       f.write(line)\n",
        "\n",
        "! python {path_checkOutputs} {str_PredArg_folder} {str_SMorphText_folder} {log_folder} {temp_input_folder_morph} {language}\n",
        "\n",
        "if not language == 'GA':\n",
        "  clear_folder(os.path.join(temp_input_folder_morph, split))\n",
        "  # For GA, files are copied from the python code called above\n",
        "  if concatenate_output_files == 'yes':\n",
        "    ! python {path_concatenate} {str_SMorphText_folder} {temp_input_folder_morph} {split}\n",
        "  else:\n",
        "    ! python {path_concatenate} {str_SMorphText_folder} {temp_input_folder_morph} {split}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iPz_wQhte3q"
      },
      "source": [
        "## 3 - Morphology processing (Irish NLP Tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqqbgzs3zqqj"
      },
      "outputs": [],
      "source": [
        "# Use if you upload structures generated from another pipeline instead of using the previous cells\n",
        "# import shutil\n",
        "# clear_folder('/content/FORGe/structures')\n",
        "# ! unzip /content/FORGe-train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TFQOgvG0laB"
      },
      "outputs": [],
      "source": [
        "# Process raw FORGe output and format it for Morphology\n",
        "\n",
        "# Read original check script\n",
        "if os.path.isfile('/content/FORGe/log/summary.txt'):\n",
        "  FORGe_log = open('/content/FORGe/log/summary.txt', 'r')\n",
        "  lines_log = FORGe_log.readlines()\n",
        "  # Get number of expected texts\n",
        "  count_strs_all_FORGe = 0\n",
        "  for line in lines_log:\n",
        "    if line.startswith('Outputs: '):\n",
        "      count_strs_all_FORGe = int(line.strip().split('Outputs: ')[-1])\n",
        "\n",
        "  print('Expected texts: '+str(count_strs_all_FORGe)+'.\\n')\n",
        "\n",
        "if language == 'GA':\n",
        "  ! python {path_FORGe2Morph} {language} {temp_input_folder_morph} {morph_input_folder}\n",
        "  clear_files(temp_input_folder_morph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "uPBqNqjkueAk"
      },
      "outputs": [],
      "source": [
        "# Call morph generator\n",
        "# v3 (fast, ~2sec/450 texts)\n",
        "\n",
        "# Run the morphology generation\n",
        "from IPython.display import HTML, display\n",
        "import progressbar\n",
        "import glob\n",
        "import codecs\n",
        "from termcolor import colored\n",
        "import re\n",
        "\n",
        "show_input = False #@param {type:\"boolean\"}\n",
        "\n",
        "if language == 'GA':\n",
        "  clear_files(morph_output_folder)\n",
        "  # To store how many texts we have in each file (used to )\n",
        "  count_strs_all_Morph = []\n",
        "  for filepath in sorted(glob.glob(os.path.join(morph_input_folder, '*.*'))):\n",
        "    count_strs_all = 0\n",
        "    head, tail = os.path.split(filepath)\n",
        "    filename = tail.rsplit('.')[0]\n",
        "    print('Processing '+filename)\n",
        "    fo = codecs.open(morph_output_folder+'/'+filename+'_out.txt', 'w', 'utf-8')\n",
        "    list_inflected_words = ! cat {filepath} | {morph_folder_name}'/flookup' -a {morph_folder_name}'/allgen.fst'\n",
        "    # print(list_inflected_words)\n",
        "\n",
        "    # Create a variable to store the outputs\n",
        "    text = ''\n",
        "    # morph returns this as list_inflected_words: ['imir+Verb+Vow+PresInd\\timríonn', '', 'Agremiação_Sportiva_Arapiraquense+Noun+Masc+Com+Pl\\t+?', '', ',\\t+?',...]\n",
        "    for word in list_inflected_words:\n",
        "      empty = 'yes'\n",
        "      input_string = ''\n",
        "      morph_returned = ''\n",
        "      morph_backup = ''\n",
        "      if re.search('\\t', word):\n",
        "        # for every space an empty string is returned; we'll ignore them later. Between two consecutive texts there is a simple \"\\t\" with nothing around. I use this to introduce linebreaks later.\n",
        "        empty = 'no'\n",
        "        input_string = word.split('\\t')[0]\n",
        "        morph_returned = word.split('\\t')[1]\n",
        "        if re.search('\\+', word):\n",
        "          morph_backup = input_string.split('+', 1)[0]\n",
        "        else:\n",
        "          morph_backup = input_string\n",
        "      out_line = ''\n",
        "      # Create each output line with the required contents\n",
        "      if show_input == True:\n",
        "        if empty == 'no':\n",
        "          if morph_returned == '':\n",
        "            if input_string == '':\n",
        "              out_line = out_line + '\\n'\n",
        "              count_strs_all += 1\n",
        "          else:\n",
        "            out_line = out_line + input_string + ': ' +'\\x1b[5;30;47m'+morph_returned+'\\x1b[0m'+'\\n'\n",
        "      else:\n",
        "        if empty == 'no':\n",
        "          if morph_returned == '+?':\n",
        "            out_line = out_line + morph_backup + ' '\n",
        "          # If the line is empty, add a line break (empty lines separate different texts in the input)\n",
        "          elif morph_returned == '':\n",
        "            if input_string == '':\n",
        "              out_line = out_line + '\\n'\n",
        "              count_strs_all += 1\n",
        "          else:\n",
        "            out_line = out_line + morph_returned + ' '\n",
        "      # add line to the other lines of the same file\n",
        "      text = text + out_line\n",
        "\n",
        "    # print('\\n----------------------\\n'+text+'\\n')\n",
        "    count_strs_all_Morph.append(count_strs_all)\n",
        "    fo.write(text+'\\n')\n",
        "    fo.close()\n",
        "\n",
        "  # Check\n",
        "  if os.path.isfile('/content/FORGe/log/summary.txt'):\n",
        "    with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "      fo.write('\\nMorphology debug\\n==================\\n\\n')\n",
        "      if not sum(count_strs_all_Morph) == count_strs_all_FORGe:\n",
        "        print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "        fo.write('ERROR! Mismatch with FORGe outputs!\\n')\n",
        "      print('\\nThere are '+str(sum(count_strs_all_Morph))+' texts.')\n",
        "      fo.write('There are '+str(sum(count_strs_all_Morph))+' texts.\\n')\n",
        "      print('Texts per file: '+str(count_strs_all_Morph))\n",
        "      fo.write('Texts per file: '+str(count_strs_all_Morph)+'\\n')\n",
        "      fo.write('---------------------------------\\n')\n",
        "  clear_files(morph_input_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsBqWCAuxyE"
      },
      "source": [
        "## 4 - Output post-processing and packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODAI93StJjVd"
      },
      "outputs": [],
      "source": [
        "# Process texts\n",
        "prefinal_output_folder = ''\n",
        "\n",
        "if language == 'GA':\n",
        "  prefinal_output_folder = morph_output_folder\n",
        "else:\n",
        "  prefinal_output_folder = os.path.join(temp_input_folder_morph, split)\n",
        "\n",
        "! python {path_postProc} {language} {prefinal_output_folder}\n",
        "\n",
        "# Check\n",
        "list_filepaths = glob.glob(os.path.join(prefinal_output_folder, '*_postproc.txt'))\n",
        "count_strs_all_postproc = []\n",
        "for filepath in sorted(list_filepaths):\n",
        "  count_strs_all = 0\n",
        "  head, tail = os.path.split(filepath)\n",
        "  fd = codecs.open(filepath, 'r', 'utf-8')\n",
        "  lines = fd.readlines()\n",
        "  x = 0\n",
        "  for line in lines:\n",
        "    if not line == '\\n':\n",
        "      count_strs_all += 1\n",
        "    x += 1\n",
        "  count_strs_all_postproc.append(count_strs_all)\n",
        "\n",
        "if os.path.isfile('/content/FORGe/log/summary.txt'):\n",
        "  with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "    fo.write('\\nPost-processing debug\\n==================\\n\\n')\n",
        "    if not sum(count_strs_all_postproc) == count_strs_all_FORGe:\n",
        "      print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "      fo.write('ERROR! Mismatch with FORGe outputs!\\n')\n",
        "    print('\\nThere are '+str(sum(count_strs_all_postproc))+' texts.')\n",
        "    fo.write('There are '+str(sum(count_strs_all_postproc))+' texts.\\n')\n",
        "    print('Texts per file: '+str(count_strs_all_postproc))\n",
        "    fo.write('Texts per file: '+str(count_strs_all_postproc)+'\\n')\n",
        "    fo.write('---------------------------------\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfQ08wHOu8eZ"
      },
      "outputs": [],
      "source": [
        "# Concatenate files\n",
        "\n",
        "# list_clean_outputs = glob.glob(os.path.join(morph_output_folder, '*_out_postproc.txt'))\n",
        "list_clean_outputs = ''\n",
        "if language == 'GA':\n",
        "  list_clean_outputs = glob.glob(os.path.join(morph_output_folder, '*_out_postproc.txt'))\n",
        "else:\n",
        "  list_clean_outputs = glob.glob(os.path.join(temp_input_folder_morph, split, '*_postproc.txt'))\n",
        "print(list_clean_outputs)\n",
        "\n",
        "filename = 'all_'+language+'_'+split+'_out.txt'\n",
        "\n",
        "with codecs.open(filename, 'w', 'utf-8') as outfile:\n",
        "  # Files need to be sorted to be concatenated in the right order\n",
        "  for fname in sorted(list_clean_outputs):\n",
        "    print('Processing '+fname)\n",
        "    with open(fname) as infile:\n",
        "      outfile.write(infile.read())\n",
        "\n",
        "# Check\n",
        "if os.path.isfile('/content/FORGe/log/summary.txt'):\n",
        "  with codecs.open('/content/FORGe/log/summary.txt', 'a', 'utf-8') as fo:\n",
        "    fo.write('\\nConcatenate debug\\n==================\\n\\n')\n",
        "    count_texts_all = len(codecs.open(filename).readlines())\n",
        "    if not count_texts_all == count_strs_all_FORGe:\n",
        "      print('\\nERROR! Mismatch with FORGe outputs!')\n",
        "      fo.write(('ERROR! Mismatch with FORGe outputs!\\n'))\n",
        "    print('\\nThere are '+str(count_texts_all)+' texts.')\n",
        "    fo.write('There are '+str(count_texts_all)+' texts.\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kRClGzfcJ5Nv",
        "outputId": "ba94e79b-17a7-4932-977a-97e5ff47229d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7dfaa4e9-6060-4efe-a64d-48d5b5f9671b\", \"WebNLG_[GA]_[test]_allLevels.zip\", 2036647)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip and download FORGe output folder to download intermediate representations\n",
        "# from google.colab import files\n",
        "# zip_name_inter = '/content/WebNLG_['+language+']_['+split+']_allLevels.zip'\n",
        "# # !zip -r {zip_name_inter} /content/FORGe/structures\n",
        "# !zip -r {zip_name_inter} /content/FORGe/structures/10-DMorphLin\n",
        "# !zip -r {zip_name_inter} /content/FORGe/structures/11-SMorphText\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "# files.download(zip_name_inter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "U_yzCQGBshN1",
        "outputId": "bcefe4c9-9e89-4abe-a3ff-59756b13fcdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6befc809-259c-4f42-960c-da4f4dbb1441\", \"WebNLG_[GA]_[test]_logs.zip\", 1611)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip FORGe log files folder\n",
        "# from google.colab import files\n",
        "# zip_name_log = '/content/WebNLG_['+language+']_['+split+']_logs.zip'\n",
        "# !zip -r {zip_name_log} /content/FORGe/log\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "# files.download(zip_name_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WQbOtHkz74xD",
        "outputId": "72abeb72-4fad-4ccb-bd1b-edd2a6c48d04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63742417-2ae2-492e-bb18-8851072bb8c8\", \"WebNLG_[GA]_inputs.zip\", 605777)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip and download conll inputs\n",
        "# from google.colab import files\n",
        "# zip_name_log = '/content/WebNLG_['+language+']_inputs.zip'\n",
        "# !zip -r {zip_name_log} /content/FORGe/structures/00-PredArg\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "# files.download(zip_name_log)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DhPOmwVKtnp0",
        "FYliSyNnOUCK",
        "0iPz_wQhte3q"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPOFB1t6gpGb/2BsEDdMvfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}